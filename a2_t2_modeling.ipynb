{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d25d71e7",
   "metadata": {},
   "source": [
    "# Modeling \n",
    "1. Context\n",
    "- Our ML task is to create models that will take in MIDI files and generate an extension of those MIDI files, so that we can indefintely continue adding to the current piece.\n",
    "- All of our models will take in the same input MIDI files and also output an extended version with an equal number of extended notes (although the time extension may differ due to how fast the notes are played)\n",
    "- Appropriate models: We determined that our final model would be a learned sequence model, since  it can learn and take into account the entire piece for its extension. However, we also wanted to test it among simpler models such as our random baseline model and an extension of Markov Chain models that require far less power in exchange for not being able to account for the whole piece. \n",
    "- Optimizations: our first 2 models (Markov Chain) will focus on perplexity, while the third model (LSTM) optimizes its cross entropy loss while training. \n",
    "\n",
    "1. Discussion\n",
    "- Baseline Model:\n",
    "  - It is a random based trivial model that randomly picks notes to extend our base MIDI file.\n",
    "  - Pros: \n",
    "    - No training, fast\n",
    "  - Cons:\n",
    "    - No musical structure at all\n",
    "    - Terrible Perplexity\n",
    "- Markov (No Seeding)\n",
    "  - This markov model is trained over our whole dataset to learn the unigrams, bigrams, and trigrams of notes and beats. However it does not account for anything in the input MIDI file.\n",
    "  - Pros\n",
    "    - Simple implementation and fast production of output\n",
    "    - The extended section will follow better musical structures learned in the dataset\n",
    "  - Cons:\n",
    "    - Can only learn short-context sequences to produce new notes\n",
    "    - The musical structure may or may not differ from the original piece\n",
    "- Markov (Seeding)\n",
    "  - This markov model learns the unigrams, bigrams and trigrams similar to the previous. The difference is that it will learn the last few notes of the MIDI input file to match its musical structure in the extension. \n",
    "  - Pros:\n",
    "    - Extension has similar musical structure to where the MIDI file ends\n",
    "  - Cons: \n",
    "    - Still only learns short-context sequences\n",
    "- LSTM \n",
    "  - This model is a stacked LSTM next token language model that learns the tokens from the REMI tokenizer.\n",
    "    - Pros: \n",
    "      - Can learn very long-contexts for the extension\n",
    "      - It can learn the rhythm and melody much better and account for when a change in rhythm is expected\n",
    "    - Cons:\n",
    "      - Complex, long training times\n",
    "      - Can overfit and produce less unique music. \n",
    "- Complexity: LSTM is the most complex, followed by Markov then Random baselinee\n",
    "- Efficiency: Random and Markov will train and produce extensions very quickly in a few seconds, while the LSTM took minutes to train\n",
    "- Implementaiton challenges:\n",
    "  - Random: Does not have a way to predict the rhythm and tempo at all\n",
    "  - Markov: Can occassionally produce very different sounding music as it continues generating notes\n",
    "  - LSTM: Hyper-parameters were difficult to tuen as it takes a long time to train the model.   \n",
    "\n",
    "# Code Walk Through"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed841af",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b85a924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pretty_midi\n",
    "from tqdm import tqdm\n",
    "import mido\n",
    "import random\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "from symusic import Score\n",
    "from miditok import REMI, TokenizerConfig\n",
    "from midiutil import MIDIFile\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985e8818",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d2fa46",
   "metadata": {},
   "source": [
    "# Setup and default functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f466362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial tokenization happening in this block\n",
    "midi_files = glob('C:/Users/sugia/Desktop/UCSD/CSE 153/A2/melody/*.mid')\n",
    "len(midi_files)\n",
    "config = TokenizerConfig(num_velocities=1, use_chords=False, use_programs=False)\n",
    "tokenizer = REMI(config)\n",
    "tokenizer.train(vocab_size=1000, files_paths=midi_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d1e0488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bar_None',\n",
       " 'Position_16',\n",
       " 'Pitch_76',\n",
       " 'Velocity_127',\n",
       " 'Duration_1.0.8',\n",
       " 'Position_24',\n",
       " 'Pitch_74',\n",
       " 'Velocity_127',\n",
       " 'Duration_2.0.8',\n",
       " 'Bar_None']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midi = Score(midi_files[0])\n",
    "tokens = tokenizer(midi)[0].tokens\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1703de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_extraction(midi_file):\n",
    "    # Q1a: Your code goes here\n",
    "    score = Score(midi_file)\n",
    "    tokens = tokenizer(score)[0].tokens\n",
    "    pitches = [int(t.split('_')[1]) for t in tokens if t.startswith(\"Pitch_\")]\n",
    "    return pitches\n",
    "\n",
    "def note_frequency(midi_files):\n",
    "    # Q1b: Your code goes here\n",
    "    freq = defaultdict(int)\n",
    "    for file in midi_files:\n",
    "        for pitch in note_extraction(file):\n",
    "            freq[pitch] += 1\n",
    "    return dict(freq)\n",
    "\n",
    "def note_unigram_probability(midi_files):\n",
    "    note_counts = note_frequency(midi_files)\n",
    "    totalNotes = sum(note_counts.values())\n",
    "    unigramProbabilities = {note : count/ totalNotes for note, count in note_counts.items()}\n",
    "    \n",
    "    # Q2: Your code goes here\n",
    "    # ...\n",
    "    \n",
    "    return unigramProbabilities\n",
    "\n",
    "def note_bigram_probability(midi_files):\n",
    "\n",
    "    bigramTransitions = defaultdict(list)\n",
    "    bigramTransitionProbabilities = defaultdict(list)\n",
    "\n",
    "    # Q3a: Your code goes here\n",
    "    bigramCounts = defaultdict(lambda: defaultdict(int))\n",
    "    for file in midi_files:\n",
    "        pitches = note_extraction(file)\n",
    "        for i, j in zip(pitches, pitches[1:]):\n",
    "            bigramCounts[i][j] += 1\n",
    "    # ...\n",
    "    T = {}\n",
    "    P = {}\n",
    "    for prev, next in bigramCounts.items():\n",
    "        nextNotes = list(next.keys())\n",
    "        counts = list(next.values())\n",
    "        total = sum(counts)\n",
    "        prob = [c/total for c in counts]\n",
    "        bigramTransitions[prev] = nextNotes\n",
    "        bigramTransitionProbabilities[prev] =  prob \n",
    "\n",
    "    \n",
    "\n",
    "    return bigramTransitions, bigramTransitionProbabilities\n",
    "\n",
    "def sample_next_note(note):\n",
    "    bigramTransitions, bigramTransitionProbabilities = note_bigram_probability(midi_files)\n",
    "    next = bigramTransitions.get(note)\n",
    "    probs = bigramTransitionProbabilities.get(note)\n",
    "    return random.choices(next, weights=probs, k=1)[0]\n",
    "\n",
    "def note_trigram_probability(midi_files):\n",
    "    trigramTransitions = defaultdict(list)\n",
    "    trigramTransitionProbabilities = defaultdict(list)\n",
    "    \n",
    "    trigram_counts = defaultdict(lambda: defaultdict(int))\n",
    "    for file in midi_files:\n",
    "        pitch = note_extraction(file)\n",
    "        for i in range(2, len(pitch)):\n",
    "            note = (pitch[i-2], pitch[i-1])\n",
    "            trigram_counts[note][pitch[i]] += 1\n",
    "    # Q5a: Your code goes here\n",
    "    # ...\n",
    "    for note, next_dict in trigram_counts.items():\n",
    "        notes  = list(next_dict.keys())\n",
    "        counts = list(next_dict.values())\n",
    "        total  = sum(counts)\n",
    "        probs  = [c/total for c in counts]\n",
    "\n",
    "        trigramTransitions[note] = notes\n",
    "        trigramTransitionProbabilities[note] = probs\n",
    "\n",
    "    return trigramTransitions, trigramTransitionProbabilities\n",
    "\n",
    "duration2length = {\n",
    "    '0.2.8': 2,  # sixteenth note, 0.25 beat in 4/4 time signature\n",
    "    '0.4.8': 4,  # eighth note, 0.5 beat in 4/4 time signature\n",
    "    '1.0.8': 8,  # quarter note, 1 beat in 4/4 time signature\n",
    "    '2.0.8': 16, # half note, 2 beats in 4/4 time signature\n",
    "    '4.0.4': 32, # whole note, 4 beats in 4/4 time signature\n",
    "}\n",
    "\n",
    "def beat_extraction(midi_file):\n",
    "    score  = Score(midi_file)\n",
    "    tokens = tokenizer(score)[0].tokens\n",
    "    output = []\n",
    "\n",
    "    for i, tok in enumerate(tokens):\n",
    "        if tok.startswith(\"Position_\"):\n",
    "            position = int(tok.split(\"_\",1)[1])\n",
    "            # look ahead for the duration token\n",
    "            if i+3 < len(tokens) and tokens[i+3].startswith(\"Duration_\"):\n",
    "                dur_str = tokens[i+3].split(\"_\",1)[1]\n",
    "                length = duration2length.get(dur_str, 0)\n",
    "                # *** skip any zero‐length ***\n",
    "                if length > 0:\n",
    "                    output.append((position, length))\n",
    "    return output\n",
    "\n",
    "def beat_bigram_probability(midi_files):\n",
    "    bigramBeatTransitions = defaultdict(list)\n",
    "    bigramBeatTransitionProbabilities = defaultdict(list)\n",
    "    counts = defaultdict(lambda: defaultdict(int))\n",
    "    for file in midi_files:\n",
    "        beat = beat_extraction(file)\n",
    "        lengths = [length for _,length in beat]\n",
    "        for i,j in zip(lengths, lengths[1:]):\n",
    "            counts[i][j] += 1\n",
    "    for prev, next in counts.items():\n",
    "        nextVal = list(next.keys())\n",
    "        cnts = list(next.values())\n",
    "        total = sum(cnts)\n",
    "        probs = [c/total for c in cnts]\n",
    "        bigramBeatTransitions[prev] = nextVal\n",
    "        bigramBeatTransitionProbabilities[prev] = probs\n",
    "    # Q7: Your code goes here\n",
    "    # ...\n",
    "    \n",
    "    return bigramBeatTransitions, bigramBeatTransitionProbabilities\n",
    "\n",
    "def beat_pos_bigram_probability(midi_files):\n",
    "    bigramBeatPosTransitions = defaultdict(list)\n",
    "    bigramBeatPosTransitionProbabilities = defaultdict(list)\n",
    "    \n",
    "    # Q8a: Your code goes here\n",
    "    # ...\n",
    "    counts = defaultdict(lambda: defaultdict(int))\n",
    "    for file in midi_files:\n",
    "        for position, length in beat_extraction(file):\n",
    "            counts[position][length] += 1\n",
    "\n",
    "    \n",
    "    for position, length in counts.items():\n",
    "        vals  = list(length.keys())\n",
    "        cnts  = list(length.values())\n",
    "        total = sum(cnts)\n",
    "        probs = [c/total for c in cnts]\n",
    "        bigramBeatPosTransitions[position]= vals\n",
    "        bigramBeatPosTransitionProbabilities[position] = probs\n",
    "\n",
    "    return bigramBeatPosTransitions, bigramBeatPosTransitionProbabilities\n",
    "\n",
    "def beat_trigram_probability(midi_files):\n",
    "    trigramBeatTransitions = defaultdict(list)\n",
    "    trigramBeatTransitionProbabilities = defaultdict(list)\n",
    "\n",
    "    # Q9a: Your code goes here\n",
    "    # ...\n",
    "    trigram_counts = defaultdict(lambda: defaultdict(int))\n",
    "    for file in midi_files:\n",
    "        beats = beat_extraction(file)\n",
    "        for (prev_pos, prev_len), (pos, length) in zip(beats, beats[1:]):\n",
    "            pair = (prev_len, pos)\n",
    "            trigram_counts[pair][length] += 1\n",
    "\n",
    "    trigramBeatTransitions = {}\n",
    "    trigramBeatTransitionProbabilities = {}\n",
    "    for pair, next in trigram_counts.items():\n",
    "        next_lengths = list(next.keys())\n",
    "        counts = list(next.values())\n",
    "        total = sum(counts)\n",
    "        probs = [c/total for c in counts]\n",
    "        trigramBeatTransitions[pair] = next_lengths\n",
    "        trigramBeatTransitionProbabilities[pair] = probs\n",
    "    return trigramBeatTransitions, trigramBeatTransitionProbabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f331a4f7",
   "metadata": {},
   "source": [
    "# Baseline Random Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261e918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extend_random_midi(\n",
    "    in_path: str,\n",
    "    out_path: str,\n",
    "    length: int = 100,\n",
    "    track_idx: int = 1,\n",
    "    channel: int = 0,\n",
    "    velocity: int = 100\n",
    "):\n",
    "    # Load all the tracks\n",
    "    mid   = mido.MidiFile(in_path)\n",
    "    track = mid.tracks[track_idx]\n",
    "    tpb   = mid.ticks_per_beat\n",
    "\n",
    "    # remove only the final End-Of-Track\n",
    "    if track and track[-1].is_meta and track[-1].type == \"end_of_track\":\n",
    "        track.pop()\n",
    "\n",
    "    # possible lengths in your 1/16-note grid\n",
    "    choices_bl = [2, 4, 8, 16, 32]\n",
    "    for _ in range(length):\n",
    "        pitch = random.randint(21, 108)\n",
    "        bl    = random.choice(choices_bl)\n",
    "        ticks = int((bl / 8.0) * tpb)\n",
    "        # based on the random choice add the note on and offs with those values\n",
    "        track.append(mido.Message(\n",
    "            \"note_on\",\n",
    "            note=pitch,\n",
    "            velocity=velocity,\n",
    "            time=0,\n",
    "            channel=channel\n",
    "        ))\n",
    "        track.append(mido.Message(\n",
    "            \"note_off\",\n",
    "            note=pitch,\n",
    "            velocity=0,\n",
    "            time=ticks,\n",
    "            channel=channel\n",
    "        ))\n",
    "\n",
    "    # re-add End-Of-Track and save\n",
    "    track.append(mido.MetaMessage(\"end_of_track\", time=0))\n",
    "    mid.save(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a0486b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "extend_random_midi(\n",
    "    \"melody/trimmed_20s/ashover4.mid\",\n",
    "    \"ashover4_baseline_ext.mid\",\n",
    "    length=20,\n",
    "    track_idx=1,\n",
    "    channel=0,\n",
    "    velocity=90\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d459359d",
   "metadata": {},
   "source": [
    "# Markov Chain Extension (No dependency on current MIDI) expansion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f6adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes_and_beats(length):\n",
    "    # Use the uni , bi, and trigrams of notes and beats here\n",
    "    unigramProbabilities = note_unigram_probability(midi_files)\n",
    "    bigramTransitions, bigramTransitionProbabilities = note_bigram_probability(midi_files)\n",
    "    trigramTransitions, trigramTransitionProbabilities = note_trigram_probability(midi_files)\n",
    "    \n",
    "    notes = []\n",
    "    for i in range(length):\n",
    "        # Choose first note from unigram\n",
    "        if i == 0:\n",
    "            next = list(unigramProbabilities.keys())\n",
    "            weights= list(unigramProbabilities.values())\n",
    "        elif i == 1:\n",
    "            # Choose second note from bigram\n",
    "            prev = notes[-1]\n",
    "            next = bigramTransitions.get(prev, list(unigramProbabilities.keys()))\n",
    "            weights= bigramTransitionProbabilities.get(prev, list(unigramProbabilities.values()))\n",
    "        else:\n",
    "            # choose every other note using trigrams\n",
    "            prev2, prev1 = notes[-2], notes[-1]\n",
    "            pair = (prev2, prev1)\n",
    "            if pair in trigramTransitions:\n",
    "                next, weights = trigramTransitions[pair], trigramTransitionProbabilities[pair]\n",
    "            elif prev1 in bigramTransitions:\n",
    "                next, weights = bigramTransitions[prev1], bigramTransitionProbabilities[prev1]\n",
    "            else:\n",
    "                next, weights = list(unigramProbabilities.keys()), list(unigramProbabilities.values())\n",
    "\n",
    "        notes.append(random.choices(next, weights, k=1)[0])\n",
    "        \n",
    "    bigramBeatPosTransitions, bigramBeatPosTransitionProbabilities = beat_pos_bigram_probability(midi_files)\n",
    "    pos = 0\n",
    "    beats = []\n",
    "    # The way we choose the beats is basically the same as above for notes except we are using the bigrams for beats and positions\n",
    "    for _ in range(length):\n",
    "        next = bigramBeatPosTransitions.get(pos, [8]) \n",
    "        weights= bigramBeatPosTransitionProbabilities.get(pos, None)\n",
    "        if weights is None:\n",
    "            weights = [1]*len(next)\n",
    "        bl = random.choices(next, weights, k=1)[0]\n",
    "        beats.append(bl)\n",
    "        pos = (pos + bl) % 32\n",
    "    return notes, beats\n",
    "\n",
    "\n",
    "\n",
    "def extend_midi(\n",
    "    input_midi_path: str,\n",
    "    output_midi_path: str,\n",
    "    length: int,\n",
    "    track_idx: int = 1,\n",
    "    channel: int   = 0,\n",
    "    velocity: int  = 100\n",
    "):\n",
    "    # load your base file\n",
    "    mid = mido.MidiFile(input_midi_path)\n",
    "\n",
    "    # pick the track you want to append to and remove its EndOfTrack\n",
    "    track = mid.tracks[track_idx]\n",
    "    track[:] = [msg for msg in track\n",
    "                if not (msg.is_meta and msg.type == 'end_of_track')]\n",
    "\n",
    "    # generate your notes + beats\n",
    "    notes, beats = generate_notes_and_beats(length)\n",
    "\n",
    "    # 4) append each new note\n",
    "    for pitch, bl in zip(notes, beats):\n",
    "        # convert your “beats” to delta-ticks\n",
    "        dur_beats = bl / 8.0              # same scale you used in addNote()\n",
    "        dur_ticks = int(dur_beats * mid.ticks_per_beat)\n",
    "\n",
    "        # note_on at delta=0 (immediately after previous event)\n",
    "        track.append(mido.Message('note_on',\n",
    "                                  note=pitch,\n",
    "                                  velocity=velocity,\n",
    "                                  time=0,\n",
    "                                  channel=channel))\n",
    "        # note_off after dur_ticks\n",
    "        track.append(mido.Message('note_off',\n",
    "                                  note=pitch,\n",
    "                                  velocity=0,\n",
    "                                  time=dur_ticks,\n",
    "                                  channel=channel))\n",
    "\n",
    "    # finally close the track again\n",
    "    track.append(mido.MetaMessage('end_of_track', time=0))\n",
    "\n",
    "    # write out a brand-new file\n",
    "    mid.save(output_midi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1acfcf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "extend_midi(\"melody/trimmed_20s/ashover4.mid\", \"ashover4_random_extended.mid\", length=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a6e556",
   "metadata": {},
   "source": [
    "# Markov Chain Extension + Seeding (Ensures reading context of the current MIDI) Expansion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669246e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_notes_and_beats(length,unigramP, bigramT, bigramP,trigramT, trigramP,beat_pos_T, beat_pos_P,seed_pitches=None,seed_beats=None):\n",
    "    # start with the seed from the midi file input\n",
    "    notes = list(seed_pitches or [])\n",
    "    beats = list(seed_beats   or [])\n",
    "\n",
    "    # Figures out which notes to add based on the the usual uni, bi and trigrams from before but under the context where the MIDI ended\n",
    "    for i in range(length):\n",
    "       \n",
    "        if len(notes) == 0:\n",
    "            choices = list(unigramP.keys())\n",
    "            weights = list(unigramP.values())\n",
    "        elif len(notes) == 1:\n",
    "            prev    = notes[-1]\n",
    "            choices = bigramT.get(prev, list(unigramP.keys()))\n",
    "            weights = bigramP.get(prev, list(unigramP.values()))\n",
    "        else:\n",
    "            prev2, prev1 = notes[-2], notes[-1]\n",
    "            pair = (prev2, prev1)\n",
    "            if pair in trigramT:\n",
    "                choices = trigramT[pair]\n",
    "                weights = trigramP[pair]\n",
    "            else:\n",
    "                choices = bigramT.get(prev1, list(unigramP.keys()))\n",
    "                weights = bigramP.get(prev1, list(unigramP.values()))\n",
    "\n",
    "        new_note = random.choices(choices, weights, k=1)[0]\n",
    "        notes.append(new_note)\n",
    "\n",
    "        # Beat generation just like in the previous model\n",
    "        pos = sum(beats) % 32\n",
    "        next_beats = beat_pos_T.get(pos, [8])\n",
    "        next_wghts = beat_pos_P.get(pos, [1])\n",
    "        new_bl = random.choices(next_beats, next_wghts, k=1)[0]\n",
    "        beats.append(new_bl)\n",
    "\n",
    "    return notes, beats\n",
    "\n",
    "# 1) extract the last N seed notes & beats from an existing track\n",
    "def extract_seed(input_midi_path, track_idx=1, n_seed=2):\n",
    "    mid = mido.MidiFile(input_midi_path)\n",
    "    ticks_per_beat = mid.ticks_per_beat\n",
    "    track = mid.tracks[track_idx]\n",
    "\n",
    "    time_cursor = 0\n",
    "    active = {}       # note_on time for each pitch\n",
    "    all_pitches = []\n",
    "    all_beats   = []\n",
    "\n",
    "    # This part extracts the last few notes and beats in the midi file\n",
    "    for msg in track:\n",
    "        time_cursor += msg.time\n",
    "        # note-on\n",
    "        if msg.type == 'note_on' and msg.velocity > 0:\n",
    "            active[msg.note] = time_cursor\n",
    "        # note-off\n",
    "        elif (msg.type == 'note_off' or (msg.type=='note_on' and msg.velocity==0)) \\\n",
    "             and msg.note in active:\n",
    "            start = active.pop(msg.note)\n",
    "            dt = time_cursor - start\n",
    "            # convert dt→your “beat units” (you used bl/8.0 earlier)\n",
    "            bl = int((dt / ticks_per_beat) * 8)\n",
    "            if bl <= 0:\n",
    "                bl = 1\n",
    "            all_pitches.append(msg.note)\n",
    "            all_beats.append(bl)\n",
    "\n",
    "    # take the last n_seed values\n",
    "    seed_pitches = all_pitches[-n_seed:]\n",
    "    seed_beats   = all_beats[-n_seed:]\n",
    "    return seed_pitches, seed_beats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf75b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_with_continuation(in_path, out_path, length):\n",
    "    # pull off the last two notes/beats as seed\n",
    "    seed_n, seed_b = extract_seed(in_path, track_idx=1, n_seed=2)\n",
    "\n",
    "    # precompute your uni, bi, trigram and beat-pos bigrams exactly as before\n",
    "    U   = note_unigram_probability(midi_files)\n",
    "    BT, BP = note_bigram_probability(midi_files)\n",
    "    TT, TP = note_trigram_probability(midi_files)\n",
    "    bPT, bPP = beat_pos_bigram_probability(midi_files)\n",
    "\n",
    "    # 3) generate new events continuing from the seed\n",
    "    notes, beats = generate_notes_and_beats(length,\n",
    "                                            U, BT, BP,\n",
    "                                            TT, TP,\n",
    "                                            bPT, bPP,\n",
    "                                            seed_pitches=seed_n,\n",
    "                                            seed_beats=seed_b)\n",
    "\n",
    "    # now use mido to read, strip EndOfTrack, append your new notes, re-add EndOfTrack\n",
    "    mid = mido.MidiFile(in_path)\n",
    "    track = mid.tracks[1]\n",
    "    track[:] = [m for m in track if not (m.is_meta and m.type=='end_of_track')]\n",
    "\n",
    "    for pitch, bl in zip(notes[len(seed_n):], beats[len(seed_b):]):\n",
    "        dur_ticks = int((bl/8.0) * mid.ticks_per_beat)\n",
    "        track.append(mido.Message('note_on',  note=pitch, velocity=100, time=0,           channel=0))\n",
    "        track.append(mido.Message('note_off', note=pitch, velocity=0,   time=dur_ticks, channel=0))\n",
    "\n",
    "    track.append(mido.MetaMessage('end_of_track', time=0))\n",
    "    mid.save(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f306df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extend_with_continuation(\"melody/trimmed_20s/ashover4.mid\", \"ashover4_seeding_extended.mid\", length=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a37ac1",
   "metadata": {},
   "source": [
    "# LSTM Model for Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72c46363",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# helper function to convert midi to token ids\n",
    "def midi_to_token_ids(path, tokenizer):\n",
    "    score  = Score(path)\n",
    "    tokens = tokenizer(score)[0].tokens\n",
    "    # look up each token in the tokenizer’s vocab\n",
    "    return [tokenizer.vocab[t] for t in tokens]\n",
    "\n",
    "\n",
    "# Our model\n",
    "class REMILanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size=256, hidden=512, nlayers=2):\n",
    "        super().__init__()\n",
    "        # This is the token embedding layer\n",
    "        # map REMI token to a vector size 256\n",
    "        # used to learn pitch, duration and bar\n",
    "        self.embed = nn.Embedding(vocab_size, emb_size)\n",
    "        # 2 Stacked LSTM layers\n",
    "        self.lstm  = nn.LSTM(emb_size, hidden, nlayers, batch_first=True)\n",
    "        # Takes each LSTM hidden-vector and linearly maps\n",
    "        # it back to `vocab_size` logits for next-token classification.\n",
    "        self.fc    = nn.Linear(hidden, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        # x: [B, T] token-ids\n",
    "        e, hidden = self.embed(x), hidden # embedding here\n",
    "        out, hidden = self.lstm(e, hidden) # Run LSTM here\n",
    "        logits = self.fc(out)        # Projecting outputs here\n",
    "        return logits, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9ec642f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: cuda\n",
      "Epoch 0: 1.7900\n",
      "Epoch 1: 1.0184\n",
      "Epoch 2: 0.8503\n",
      "Epoch 3: 0.7478\n",
      "Epoch 4: 0.6852\n",
      "Epoch 5: 0.6362\n",
      "Epoch 6: 0.6040\n",
      "Epoch 7: 0.5787\n",
      "Epoch 8: 0.5564\n",
      "Epoch 9: 0.5377\n",
      "Epoch 10: 0.5198\n",
      "Epoch 11: 0.5040\n",
      "Epoch 12: 0.4897\n",
      "Epoch 13: 0.4717\n",
      "Epoch 14: 0.4560\n",
      "Epoch 15: 0.4388\n",
      "Epoch 16: 0.4223\n",
      "Epoch 17: 0.4025\n",
      "Epoch 18: 0.3853\n",
      "Epoch 19: 0.3746\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This section is responsible for the training of our model\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, data, seq_len=128):\n",
    "        # data: a single long list of token-IDs\n",
    "        self.v, self.L = torch.tensor(data), len(data)\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.L - 1) // self.seq_len\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        i0 = i * self.seq_len\n",
    "        x  = self.v[i0 : i0 + self.seq_len]\n",
    "        y  = self.v[i0 + 1 : i0 + 1 + self.seq_len]\n",
    "        return x, y\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "print(\"Training on:\", device)\n",
    "\n",
    "# assemble your corpus\n",
    "all_ids = []\n",
    "bar_id   = tokenizer.vocab[\"Bar_None\"]\n",
    "\n",
    "for f in midi_files:\n",
    "    all_ids.extend(midi_to_token_ids(f, tokenizer))\n",
    "    all_ids.append(bar_id)\n",
    "\n",
    "ds     = SeqDataset(all_ids, seq_len=256)\n",
    "loader = DataLoader(ds, batch_size=16, shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "model = REMILanguageModel(tokenizer.vocab_size).to(device)\n",
    "opt   = torch.optim.Adam(model.parameters(), 1e-3)\n",
    "ce    = nn.CrossEntropyLoss()\n",
    "# Training for 5 epochs currently and optimizes for cross entropy loss\n",
    "# for epoch in range(5):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#     for x, y in loader:\n",
    "#         logits, _ = model(x)            # [B, T, V]\n",
    "#         loss = ce(logits.view(-1, logits.size(-1)),\n",
    "#                   y.view(-1))\n",
    "#         opt.zero_grad(); loss.backward()\n",
    "#         opt.step()\n",
    "#         total_loss += loss.item()\n",
    "#     print(f\"Epoch {epoch}: {total_loss/len(loader):.4f}\")\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for x, y in loader:\n",
    "        # 🟢 move each batch to GPU (non_blocking since pin_memory=True)\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        logits, _ = model(x)                          # now runs on GPU\n",
    "        B, T, V    = logits.shape\n",
    "        loss       = ce(logits.view(-1, V), y.view(-1))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch}: {total_loss/len(loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "766b8987",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sample_from_model(model, seed_ids, length, top_k=5, temperature=1.0, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    seq = seed_ids.copy()\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Start generating the new tokens\n",
    "    with torch.no_grad():\n",
    "        hidden = None\n",
    "        # prime with the seed\n",
    "        for tok in seed_ids:\n",
    "            inp = torch.tensor([[tok]], device=device)\n",
    "            _, hidden = model(inp, hidden)\n",
    "\n",
    "        for _ in range(length):\n",
    "            # look at the last token, then get the next one\n",
    "            inp    = torch.tensor([[seq[-1]]], device=device)\n",
    "            logits, hidden = model(inp, hidden)      # [1,1,vocab]\n",
    "            logits = (logits[0, -1] / temperature)    # [vocab]\n",
    "            # Get the top k highest logits and sample the highest probability  for us to append\n",
    "            vals, idxs = torch.topk(logits, top_k)    # top logits\n",
    "            probs      = F.softmax(vals, dim=0)       # top probabilities\n",
    "            choice     = torch.multinomial(probs, 1)  # Sample the new choice\n",
    "            new_id     = idxs[choice].item()\n",
    "            seq.append(new_id) # Add the new token\n",
    "\n",
    "    return seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6315346a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote → song_neural_ext.mid\n"
     ]
    }
   ],
   "source": [
    "# Pares the last 64 notes for context for how to start the extension\n",
    "def extract_token_seed(path, tokenizer, n_seed=64):\n",
    "    full_ids = midi_to_token_ids(path, tokenizer)\n",
    "    # grab the final n_seed IDs\n",
    "    return full_ids[-n_seed:]\n",
    "\n",
    "def note_extraction(midi_or_tokens):\n",
    "    # if someone passed in a bare list of tokens, just use it\n",
    "    if isinstance(midi_or_tokens, list):\n",
    "        tokens = midi_or_tokens\n",
    "    else:\n",
    "        # otherwise assume it's a file‐path or MidiFile and run Score()\n",
    "        score  = Score(midi_or_tokens)\n",
    "        tokens = tokenizer(score)[0].tokens\n",
    "\n",
    "    pitches = [int(t.split(\"_\",1)[1])\n",
    "               for t in tokens\n",
    "               if t.startswith(\"Pitch_\")]\n",
    "    return pitches\n",
    "\n",
    "def beat_extraction(midi_or_tokens):\n",
    "    if isinstance(midi_or_tokens, list):\n",
    "        tokens = midi_or_tokens\n",
    "    else:\n",
    "        score  = Score(midi_or_tokens)\n",
    "        tokens = tokenizer(score)[0].tokens\n",
    "\n",
    "    output = []\n",
    "    for i, tok in enumerate(tokens):\n",
    "        if tok.startswith(\"Position_\"):\n",
    "            pos = int(tok.split(\"_\",1)[1])\n",
    "            # find the Duration_\n",
    "            if i+3 < len(tokens) and tokens[i+3].startswith(\"Duration_\"):\n",
    "                dur_str = tokens[i+3].split(\"_\",1)[1]\n",
    "                bl      = duration2length.get(dur_str, 0)\n",
    "                if bl > 0:\n",
    "                    output.append((pos, bl))\n",
    "    return output\n",
    "\n",
    "id2token = {v:k for k,v in tokenizer.vocab.items()}\n",
    "\n",
    "# Convert from tokens back into pitches and beats\n",
    "def notes_beats_from_ids(ids: list[int]):\n",
    "    \n",
    "    # 1) decode into REMI tokens\n",
    "    events = [id2token[i] for i in ids]\n",
    "\n",
    "    # 2) fake‐up a minimal Score-like container for your old extractors\n",
    "    class FakeScore:\n",
    "        def __init__(self, tokens): self.tokens = tokens\n",
    "    fake = FakeScore(events)\n",
    "\n",
    "    # 3) reuse your existing functions\n",
    "    pitches = note_extraction(fake.tokens)\n",
    "    beats   = beat_extraction(events)\n",
    "    return pitches, beats\n",
    "# add the new notes to the original MIDI\n",
    "def extend_midi(\n",
    "    in_path: str,\n",
    "    out_path: str,\n",
    "    new_pitches: list[int],\n",
    "    new_beats:   list[int],\n",
    "    track_idx:  int = 1,\n",
    "    channel:    int = 0,\n",
    "    velocity:   int = 100\n",
    "):\n",
    "    mid   = mido.MidiFile(in_path)\n",
    "    track = mid.tracks[track_idx]\n",
    "    tpb   = mid.ticks_per_beat\n",
    "\n",
    "    # drop only the final End of track\n",
    "    if track and track[-1].is_meta and track[-1].type==\"end_of_track\":\n",
    "        track.pop()\n",
    "    # Append the new beats and notes again\n",
    "    for p, bl in zip(new_pitches, new_beats):\n",
    "        ticks = int((bl/8.0)*tpb)\n",
    "        track.append(mido.Message(\"note_on\",  note=p, velocity=velocity, time=0,      channel=channel))\n",
    "        track.append(mido.Message(\"note_off\", note=p, velocity=0,       time=ticks, channel=channel))\n",
    "\n",
    "    track.append(mido.MetaMessage(\"end_of_track\", time=0))\n",
    "    mid.save(out_path)\n",
    "\n",
    "\n",
    "# Running everything to make the new file\n",
    "if __name__ == \"__main__\":\n",
    "    IN  = \"melody/trimmed_20s/ashover4.mid\"\n",
    "    OUT = \"song_neural_ext.mid\"\n",
    "\n",
    "    # a) grab the last 64 REMI-IDs as seed\n",
    "    seed_ids = extract_token_seed(IN, tokenizer, n_seed=64)\n",
    "\n",
    "    # b) sample 256 new IDs\n",
    "    sampled = sample_from_model(model, seed_ids, length=256, top_k=5, temperature=1.0)\n",
    "\n",
    "    # c) decode & extract pitch/beat\n",
    "    new_p, new_b = notes_beats_from_ids(sampled)\n",
    " \n",
    "    # d) append them onto your original MIDI\n",
    "    # lengths_only = [ length for (_pos, length) in new_b ]\n",
    "\n",
    "    min_bl = 4   # quarter-note at 120 BPM\n",
    "\n",
    "    # 1) unpack each (pos,bl) → apply clamp only to bl\n",
    "    clamped_beats = [ max(bl, min_bl) for (_, bl) in new_b ]\n",
    "\n",
    "    # 2) still drop the positional seed if you want:\n",
    "    lengths_only = clamped_beats[len(new_b) - len(clamped_beats):]\n",
    "\n",
    "    extend_midi(\n",
    "        IN,\n",
    "        OUT,\n",
    "        new_p,          # [pitch1, pitch2, …]\n",
    "        lengths_only,   # [len1,   len2,   …]\n",
    "        track_idx=1,\n",
    "        channel=0\n",
    "    )\n",
    "    print(\"Wrote →\", OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417d2494",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
