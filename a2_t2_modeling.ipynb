{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b85a924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pretty_midi\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e42eccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidiDataset(Dataset):\n",
    "    def __init__(self, midi_dir, seq_len=200, step=0.1):\n",
    "        self.paths = glob.glob(os.path.join(midi_dir, '*.midi'))\n",
    "        self.seq_len = seq_len\n",
    "        self.step = step  # seconds per timestep\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pm = pretty_midi.PrettyMIDI(self.paths[idx])\n",
    "        pr = pm.get_piano_roll(fs=1/self.step)\n",
    "        pr = (pr > 0).astype(float)\n",
    "        pr = pr[:, :self.seq_len]\n",
    "        if pr.shape[1] < self.seq_len:\n",
    "            pad = np.zeros((128, self.seq_len - pr.shape[1]))\n",
    "            pr = np.concatenate([pr, pad], axis=1)\n",
    "        # Split melody/harmony proxies:\n",
    "        melody = pr[::2].T   # (T, 64)\n",
    "        harmony = pr[1::2].T # (T, 64)\n",
    "        return torch.from_numpy(melody), torch.from_numpy(harmony)\n",
    "\n",
    "# Instantiate dataset & loader\n",
    "seq_len = 200\n",
    "midi_trimmed_dir = r\"C:\\Users\\sugia\\Desktop\\UCSD\\CSE 153\\A2\\maestro-v3.0.0\\midi\\trimmed_20s\"\n",
    "dataset = MidiDataset(midi_trimmed_dir, seq_len=seq_len)\n",
    "# Ensure directory contains MIDI files\n",
    "assert len(dataset) > 0, f\"No MIDI files found in {midi_trimmed_dir}. Please check the directory path.\"\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "class HarmonizerLSTM(nn.Module):\n",
    "    def __init__(self, input_dim=64, hidden_dim=128, output_dim=64):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out)\n",
    "        return self.activation(out)\n",
    "\n",
    "model = HarmonizerLSTM().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b3103f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 80/80 [00:04<00:00, 18.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 avg loss: 0.2035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 80/80 [00:03<00:00, 20.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 avg loss: 0.0698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 80/80 [00:04<00:00, 19.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 avg loss: 0.0682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 80/80 [00:04<00:00, 19.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 avg loss: 0.0671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 80/80 [00:04<00:00, 18.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 avg loss: 0.0663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 80/80 [00:03<00:00, 20.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 avg loss: 0.0657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 80/80 [00:04<00:00, 18.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 avg loss: 0.0653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 80/80 [00:04<00:00, 17.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 avg loss: 0.0649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 80/80 [00:04<00:00, 18.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 avg loss: 0.0644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 80/80 [00:04<00:00, 18.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 avg loss: 0.0642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 80/80 [00:04<00:00, 18.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 avg loss: 0.0638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 80/80 [00:04<00:00, 16.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 avg loss: 0.0635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 80/80 [00:04<00:00, 19.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 avg loss: 0.0633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 80/80 [00:03<00:00, 20.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 avg loss: 0.0631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 80/80 [00:04<00:00, 19.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 avg loss: 0.0629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 80/80 [00:04<00:00, 18.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 avg loss: 0.0628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 80/80 [00:04<00:00, 18.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 avg loss: 0.0626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 80/80 [00:04<00:00, 18.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 avg loss: 0.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 80/80 [00:04<00:00, 18.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 avg loss: 0.0623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 80/80 [00:06<00:00, 12.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 avg loss: 0.0623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for mel, harm in tqdm(dataloader, desc=f\"Epoch {epoch+1}\"):\n",
    "        mel = mel.float().to(device)\n",
    "        harm = harm.float().to(device)\n",
    "        pred = model(mel)\n",
    "        loss = criterion(pred, harm)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} avg loss: {total_loss/len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f4f3a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating harmonization for: C:\\Users\\sugia\\Desktop\\UCSD\\CSE 153\\A2\\maestro-v3.0.0\\midi\\trimmed_20s\\MIDI-UNPROCESSED_01-03_R1_2014_MID--AUDIO_03_R1_2014_wav--4.midi\n",
      "Harmonization complete. Saved to 'harmonized_output_NEW.mid'.\n"
     ]
    }
   ],
   "source": [
    "# Generation & MIDI Export (corrected):\n",
    "idx = 10\n",
    "input_path = dataset.paths[idx]\n",
    "print(f\"Generating harmonization for: {input_path}\")\n",
    "\n",
    "# Load melody-only piano-roll\n",
    "melody, _ = dataset[idx]              # shape: (T, 64)\n",
    "melody = melody.unsqueeze(0).float().to(device)  # shape: (1, T, 64)\n",
    "\n",
    "# Generate harmony\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    raw = model(melody)[0].cpu().numpy()       # raw shape: (T, 64)\n",
    "    pred_harm = raw.T                          # shape: (64, T)\n",
    "\n",
    "# Reconstruct full piano-roll by interleaving melody & predicted harmony\n",
    "full_roll = np.zeros((128, seq_len))\n",
    "# Squeeze out batch dim before transpose: melody.squeeze(0) -> (T,64)\n",
    "full_roll[::2] = melody.squeeze(0).cpu().numpy().T    # shape: (64, T)\n",
    "full_roll[1::2] = (pred_harm > 0.5).astype(int)       # shape: (64, T)\n",
    "\n",
    "# Convert piano-roll to PrettyMIDI\n",
    "pm_out = pretty_midi.PrettyMIDI()\n",
    "inst = pretty_midi.Instrument(program=0)\n",
    "for pitch in range(128):\n",
    "    frames = full_roll[pitch]\n",
    "    # detect on/off transitions\n",
    "    on_idxs = np.where((frames[:-1] == 0) & (frames[1:] == 1))[0] + 1\n",
    "    off_idxs = np.where((frames[:-1] == 1) & (frames[1:] == 0))[0] + 1\n",
    "    for on, off in zip(on_idxs, off_idxs):\n",
    "        inst.notes.append(\n",
    "            pretty_midi.Note(\n",
    "                velocity=100,\n",
    "                pitch=pitch,\n",
    "                start=on * dataset.step,\n",
    "                end=off * dataset.step\n",
    "            )\n",
    "        )\n",
    "pm_out.instruments.append(inst)\n",
    "pm_out.write('harmonized_output_NEW.mid')\n",
    "\n",
    "print(\"Harmonization complete. Saved to 'harmonized_output_NEW.mid'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adcd8df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harmonizing: C:\\Users\\sugia\\Desktop\\UCSD\\CSE 153\\A2\\Twinkle Twinkle Little Star (MIDI Version).midi\n",
      "Original length: 53.0s (530 frames)\n",
      "Saved → Twinkle Twinkle Little Star (MIDI Version)_harmonized.mid (≈ 53.0s)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import pretty_midi\n",
    "\n",
    "# 6.1 Point this at any .mid/.midi file\n",
    "input_path = r\"C:\\Users\\sugia\\Desktop\\UCSD\\CSE 153\\A2\\Twinkle Twinkle Little Star (MIDI Version).midi\"\n",
    "print(f\"Harmonizing: {input_path}\")\n",
    "\n",
    "# 6.2 Load and get the full piano-roll\n",
    "orig_pm = pretty_midi.PrettyMIDI(input_path)\n",
    "fs      = 1.0 / dataset.step            # frames per second\n",
    "pr_full = orig_pm.get_piano_roll(fs=fs) # shape (128, T_full)\n",
    "\n",
    "T_full = pr_full.shape[1]\n",
    "print(f\"Original length: {T_full*dataset.step:.1f}s ({T_full} frames)\")\n",
    "\n",
    "# 6.3 Extract melody features (even rows → 64 dims)\n",
    "mel = pr_full[::2, :].T.astype(np.float32)          # (T_full, 64)\n",
    "mel_tensor = torch.from_numpy(mel).unsqueeze(0).to(device)  # (1, T_full, 64)\n",
    "\n",
    "# 6.4 Predict harmony\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out      = model(mel_tensor)              # (1, T_full, 64)\n",
    "    pred_h   = out[0].cpu().numpy().T         # (64, T_full)\n",
    "    pred_bin = (pred_h > 0.5).astype(int)     # (64, T_full)\n",
    "\n",
    "# 6.5 Reconstruct a full 128×T_full piano-roll\n",
    "full_roll      = np.zeros((128, T_full), dtype=int)\n",
    "full_roll[::2] = mel.T                       # melody back in\n",
    "full_roll[1::2]= pred_bin                    # predicted harmony\n",
    "\n",
    "# 6.6 Convert back to MIDI & save\n",
    "pm_out = pretty_midi.PrettyMIDI()\n",
    "inst   = pretty_midi.Instrument(program=0, name=\"Harmonized\")\n",
    "step   = dataset.step\n",
    "\n",
    "for pitch in range(128):\n",
    "    frames = full_roll[pitch]\n",
    "    # pad to detect on/off\n",
    "    padded = np.concatenate([[0], frames, [0]])\n",
    "    on_ix  = np.where((padded[:-1]==0)&(padded[1:]==1))[0]\n",
    "    off_ix = np.where((padded[:-1]==1)&(padded[1:]==0))[0]\n",
    "    for on, off in zip(on_ix, off_ix):\n",
    "        inst.notes.append(pretty_midi.Note(\n",
    "            velocity=100,\n",
    "            pitch=pitch,\n",
    "            start=on  * step,\n",
    "            end  =off * step\n",
    "        ))\n",
    "\n",
    "pm_out.instruments.append(inst)\n",
    "out_file = os.path.splitext(os.path.basename(input_path))[0] + \"_harmonized.mid\"\n",
    "pm_out.write(out_file)\n",
    "print(f\"Saved → {out_file} (≈ {T_full*step:.1f}s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefea368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More Complex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "994d9582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, TimeDistributed, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d7a4b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Configuration\n",
    "# =====================\n",
    "MIDI_PATH = r\"C:\\Users\\sugia\\Desktop\\UCSD\\CSE 153\\A2\\maestro-v3.0.0\\midi\\trimmed_20s\"\n",
    "FRAME_RATE = 50        # lower frame rate for fewer time steps\n",
    "SEQ_LENGTH = 100       # time steps per training sequence\n",
    "N_NOTES = 128          # MIDI note range\n",
    "BATCH_SIZE = 64        # larger batch for faster GPU utilization\n",
    "EPOCHS = 10            # fewer epochs\n",
    "MODEL_CHECKPOINT = \"bilstm_harmony_best.h5\"\n",
    "\n",
    "# =====================\n",
    "# Data Preprocessing\n",
    "# =====================\n",
    "def midi_to_piano_roll(pm: pretty_midi.PrettyMIDI, fs: int = FRAME_RATE) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert a PrettyMIDI object into a piano-roll representation.\n",
    "    Returns an array of shape (N_NOTES, T) where T = duration * fs.\n",
    "    \"\"\"\n",
    "    return pm.get_piano_roll(fs=fs)\n",
    "\n",
    "\n",
    "def load_data(midi_folder: str):\n",
    "    \"\"\"\n",
    "    Load all MIDI files, extract melody and harmony tracks, convert to sequences.\n",
    "    Assumes instrument 0 is melody; all others summed as harmony.\n",
    "    Returns X (melody) and Y (harmony) as numpy arrays with shape (num_examples, SEQ_LENGTH, N_NOTES).\n",
    "    \"\"\"\n",
    "    X_list, Y_list = [], []\n",
    "    for path in glob.glob(os.path.join(midi_folder, \"*.mid\")) + glob.glob(os.path.join(midi_folder, \"*.midi\")):\n",
    "        pm = pretty_midi.PrettyMIDI(path)\n",
    "        # Melody = first instrument\n",
    "        melody_roll = midi_to_piano_roll(pm.instruments[0])\n",
    "        # Harmony = sum of all other instruments; if none, zeros\n",
    "        if len(pm.instruments) > 1:\n",
    "            harmony_roll = np.zeros_like(melody_roll)\n",
    "            for inst in pm.instruments[1:]:\n",
    "                harmony_roll += inst.get_piano_roll(fs=FRAME_RATE)\n",
    "        else:\n",
    "            harmony_roll = np.zeros_like(melody_roll)\n",
    "\n",
    "        # Binarize\n",
    "        melody_bin = (melody_roll > 0).astype(np.float32)\n",
    "        harmony_bin = (harmony_roll > 0).astype(np.float32)\n",
    "\n",
    "        T = melody_bin.shape[1]\n",
    "        # Split into fixed-length segments\n",
    "        for start in range(0, T - SEQ_LENGTH, SEQ_LENGTH):\n",
    "            end = start + SEQ_LENGTH\n",
    "            X_list.append(melody_bin[:, start:end].T)\n",
    "            Y_list.append(harmony_bin[:, start:end].T)\n",
    "\n",
    "    X = np.array(X_list)\n",
    "    Y = np.array(Y_list)\n",
    "    return X, Y\n",
    "\n",
    "# Load and split dataset\n",
    "data_X, data_Y = load_data(MIDI_PATH)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(data_X, data_Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8174772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m263,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_5 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m394,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">690,304</span> (2.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m690,304\u001b[0m (2.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">690,304</span> (2.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m690,304\u001b[0m (2.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.0014 - loss: 0.1446"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 342ms/step - accuracy: 0.0014 - loss: 0.1440 - val_accuracy: 0.0000e+00 - val_loss: 4.2603e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - accuracy: 0.0000e+00 - loss: 3.4713e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 400ms/step - accuracy: 0.0000e+00 - loss: 3.4676e-04 - val_accuracy: 0.0000e+00 - val_loss: 1.9382e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523ms/step - accuracy: 0.0000e+00 - loss: 1.6875e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 535ms/step - accuracy: 0.0000e+00 - loss: 1.6863e-04 - val_accuracy: 0.0000e+00 - val_loss: 1.1295e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.0000e+00 - loss: 1.0170e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 427ms/step - accuracy: 0.0000e+00 - loss: 1.0164e-04 - val_accuracy: 0.0000e+00 - val_loss: 7.4776e-05\n",
      "Epoch 5/10\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - accuracy: 0.0000e+00 - loss: 6.8696e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 373ms/step - accuracy: 0.0000e+00 - loss: 6.8662e-05 - val_accuracy: 0.0000e+00 - val_loss: 5.3468e-05\n",
      "Epoch 6/10\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.0000e+00 - loss: 4.9779e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 395ms/step - accuracy: 0.0000e+00 - loss: 4.9758e-05 - val_accuracy: 0.0000e+00 - val_loss: 4.0250e-05\n",
      "Epoch 7/10\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.0000e+00 - loss: 3.7824e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 383ms/step - accuracy: 0.0000e+00 - loss: 3.7810e-05 - val_accuracy: 0.0000e+00 - val_loss: 3.1422e-05\n",
      "Epoch 8/10\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - accuracy: 0.0000e+00 - loss: 2.9734e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 403ms/step - accuracy: 0.0000e+00 - loss: 2.9725e-05 - val_accuracy: 0.0000e+00 - val_loss: 2.5207e-05\n",
      "Epoch 9/10\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - accuracy: 0.0000e+00 - loss: 2.3982e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 434ms/step - accuracy: 0.0000e+00 - loss: 2.3975e-05 - val_accuracy: 0.0000e+00 - val_loss: 2.0649e-05\n",
      "Epoch 10/10\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515ms/step - accuracy: 0.0000e+00 - loss: 1.9729e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 529ms/step - accuracy: 0.0000e+00 - loss: 1.9724e-05 - val_accuracy: 0.0000e+00 - val_loss: 1.7200e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# Model Definition (Smaller)\n",
    "# =====================\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(128, return_sequences=True), input_shape=(SEQ_LENGTH, N_NOTES)),\n",
    "    Bidirectional(LSTM(128, return_sequences=True)),\n",
    "    TimeDistributed(Dense(N_NOTES, activation='sigmoid'))\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# =====================\n",
    "# Training with Early Stopping\n",
    "# =====================\n",
    "checkpoint_cb = ModelCheckpoint(MODEL_CHECKPOINT, save_best_only=True, monitor='val_loss')\n",
    "early_cb = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "model.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[checkpoint_cb, early_cb]\n",
    ")\n",
    "model.save(\"bilstm_harmony_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9d798c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_harmony(input_midi: str, output_midi: str, model_path: str = MODEL_CHECKPOINT):\n",
    "    gen_model = load_model(model_path)\n",
    "    pm = pretty_midi.PrettyMIDI(input_midi)\n",
    "    melody_roll = midi_to_piano_roll(pm.instruments[0])\n",
    "    melody_bin = (melody_roll > 0).astype(np.float32)\n",
    "    T = melody_bin.shape[1]\n",
    "    pad = (SEQ_LENGTH - (T % SEQ_LENGTH)) % SEQ_LENGTH\n",
    "    if pad > 0:\n",
    "        melody_bin = np.pad(melody_bin, ((0,0),(0,pad)), mode='constant')\n",
    "\n",
    "    segments = [melody_bin[:, i:i+SEQ_LENGTH].T for i in range(0, melody_bin.shape[1], SEQ_LENGTH)]\n",
    "    preds = gen_model.predict(np.array(segments), batch_size=1)\n",
    "    harmony_bin = np.vstack(preds).T[:, :T]\n",
    "\n",
    "    harmony_pm = pretty_midi.PrettyMIDI()\n",
    "    piano_inst = pretty_midi.Instrument(program=0)\n",
    "    times = np.arange(harmony_bin.shape[1]) / FRAME_RATE\n",
    "    for note in range(N_NOTES):\n",
    "        active = False\n",
    "        for idx, t in enumerate(times):\n",
    "            if harmony_bin[note, idx] > 0.5 and not active:\n",
    "                active = True; start_t = t\n",
    "            elif active and (harmony_bin[note, idx] <= 0.5 or idx == len(times)-1):\n",
    "                piano_inst.notes.append(pretty_midi.Note(100, note, start_t, t))\n",
    "                active = False\n",
    "    harmony_pm.instruments.extend([piano_inst] + pm.instruments)\n",
    "    harmony_pm.write(output_midi)\n",
    "    print(f\"Harmony generated and saved to {output_midi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2293a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step\n",
      "Harmony generated and saved to C:\\Users\\sugia\\Desktop\\UCSD\\CSE 153\\A2\\sample_harmonization2.midi\n"
     ]
    }
   ],
   "source": [
    "# input_file = r\"C:\\Users\\sugia\\Desktop\\UCSD\\CSE 153\\A2\\maestro-v3.0.0\\midi\\trimmed_20s\\MIDI-UNPROCESSED_01-03_R1_2014_MID--AUDIO_03_R1_2014_wav--4.midi\"\n",
    "# output_file = r\"C:\\Users\\sugia\\Desktop\\UCSD\\CSE 153\\A2\\sample_harmonization.midi\"\n",
    "\n",
    "input_file = r\"C:\\Users\\sugia\\Desktop\\UCSD\\CSE 153\\A2\\maestro-v3.0.0\\midi\\trimmed_20s\\MIDI-Unprocessed_01_R1_2008_01-04_ORIG_MID--AUDIO_01_R1_2008_wav--1.midi\"\n",
    "output_file = r\"C:\\Users\\sugia\\Desktop\\UCSD\\CSE 153\\A2\\sample_harmonization2.midi\"\n",
    "generate_harmony(input_file, output_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088a5124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
